{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29374061",
   "metadata": {},
   "source": [
    "# Step1. Read in the parsed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "583f84b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T00:13:27.807043Z",
     "start_time": "2022-12-05T00:13:27.803166Z"
    }
   },
   "outputs": [],
   "source": [
    "# import useful libraries for data preprocessing\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg as LA\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc193f59",
   "metadata": {},
   "source": [
    "Run this cell to check your current working directory. It should return the top folder \"machine-learning-assisted-khovanov-homology\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05997dd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-04T23:34:02.772222Z",
     "start_time": "2022-12-04T23:34:02.765240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/guoyihan/Documents/GitHub/MAT_180_ML_Projects/machine-learning-assisted-khovanov-homology/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01c1cdda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-04T23:34:04.106057Z",
     "start_time": "2022-12-04T23:34:04.102389Z"
    }
   },
   "outputs": [],
   "source": [
    "#Run this cell once if still in the notebooks folder.\n",
    "#Note that running this command multiple times might get you too high in the directory tree so be \n",
    "#cautious running this cell\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c451adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression with dataset_no_repeats.csv dataset.\n",
    "# change the dataset to get new report for prediction using total free part\n",
    "df = pd.read_csv(\"data/dataset_C.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a01f4d57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>braid</th>\n",
       "      <th>components</th>\n",
       "      <th>khovanov_homology</th>\n",
       "      <th>free_part</th>\n",
       "      <th>torsion_part</th>\n",
       "      <th>free_part_count</th>\n",
       "      <th>torsion_part_count</th>\n",
       "      <th>total_num_FP_per_row</th>\n",
       "      <th>total_num_FP_per_column</th>\n",
       "      <th>jones_polynomial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2, 2, 1, -2, 2, 1, -1, -1, 2]</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: {0: Z}, 3: {0: Z, 1: 0, 2: 0, 3: 0}, 5: {0...</td>\n",
       "      <td>{(1, 0): 1, (3, 0): 1, (5, 2): 1, (9, 3): 1}</td>\n",
       "      <td>{(7, 3): {2: 1}}</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: 1, 3: 1, 5: 1, 9: 1}</td>\n",
       "      <td>{0: 2, 2: 1, 3: 1}</td>\n",
       "      <td>{1: 1, 3: 1, 4: -1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-2, -1, 1, -3, -1, 2, -3, -2, -1]</td>\n",
       "      <td>1</td>\n",
       "      <td>{-13: {-6: 0, -5: Z, -4: 0}, -11: {-6: 0, -5: ...</td>\n",
       "      <td>{(-13, -5): 1, (-9, -4): 1, (-9, -3): 1, (-7, ...</td>\n",
       "      <td>{(-11, -4): {2: 1}, (-7, -2): {2: 1}, (-5, -1)...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>{-13: 1, -9: 2, -7: 1, -5: 1, -3: 2, -1: 1}</td>\n",
       "      <td>{-5: 1, -4: 1, -3: 1, -2: 2, -1: 1, 0: 2}</td>\n",
       "      <td>{-6: -1, -5: 1, -4: -1, -3: 2, -2: -1, -1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-3, -2, 3, -2, -1, -1, 1, -3, -1]</td>\n",
       "      <td>3</td>\n",
       "      <td>{-15: {-6: Z}, -13: {-6: Z, -5: 0, -4: 0, -3: ...</td>\n",
       "      <td>{(-15, -6): 1, (-13, -6): 1, (-11, -4): 2, (-9...</td>\n",
       "      <td>{(-9, -3): {2: 1}, (-5, -1): {2: 1}}</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>{-15: 1, -13: 1, -11: 2, -9: 1, -7: 3, -5: 1, ...</td>\n",
       "      <td>{-6: 2, -4: 3, -3: 1, -2: 3, -1: 1, 0: 2}</td>\n",
       "      <td>{-7: 1, -5: 2, -4: -1, -3: 2, -2: -1, -1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[3, 3, 2, 3, -1, -2, 2, 3, 3]</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: {-1: 0, 0: 0}, 3: {-1: 0, 0: Z, 1: 0, 2: 0...</td>\n",
       "      <td>{(3, 0): 1, (5, 0): 1, (7, 2): 1, (11, 3): 1, ...</td>\n",
       "      <td>{(9, 3): {2: 1}, (13, 5): {2: 1}}</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>{3: 1, 5: 1, 7: 1, 11: 2, 15: 1}</td>\n",
       "      <td>{0: 2, 2: 1, 3: 1, 4: 1, 5: 1}</td>\n",
       "      <td>{2: 1, 4: 1, 5: -1, 6: 1, 7: -1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-3, -3, 2, -2, 2, 1, -3, -3, -3]</td>\n",
       "      <td>1</td>\n",
       "      <td>{-15: {-5: Z}, -13: {-5: 0, -4: C2}, -11: {-5:...</td>\n",
       "      <td>{(-15, -5): 1, (-11, -4): 1, (-11, -3): 1, (-7...</td>\n",
       "      <td>{(-13, -4): {2: 1}, (-9, -2): {2: 1}}</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>{-15: 1, -11: 2, -7: 1, -5: 1, -3: 1}</td>\n",
       "      <td>{-5: 1, -4: 1, -3: 1, -2: 1, 0: 2}</td>\n",
       "      <td>{-7: -1, -6: 1, -5: -1, -4: 1, -2: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>[3, 1, 3, -1, -1, -1, -1, -1, -1]</td>\n",
       "      <td>3</td>\n",
       "      <td>{-17: {-6: 0, -5: 0}, -15: {-6: 0, -5: Z, -4: ...</td>\n",
       "      <td>{(-15, -5): 1, (-13, -5): 1, (-11, -4): 1, (-1...</td>\n",
       "      <td>{(-13, -4): {2: 1}, (-11, -4): {2: 1}, (-9, -2...</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>{-15: 1, -13: 1, -11: 3, -9: 3, -7: 3, -5: 4, ...</td>\n",
       "      <td>{-5: 2, -4: 2, -3: 4, -2: 4, -1: 2, 0: 6, 2: 4}</td>\n",
       "      <td>{-7: -1, -5: -1, -3: 1, -2: 1, -1: 2, 0: 1, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2527</th>\n",
       "      <td>[2, 2, 2, -1, -2, -3, -2, -1, -3]</td>\n",
       "      <td>1</td>\n",
       "      <td>{-11: {-6: 0, -5: Z, -4: 0}, -9: {-6: 0, -5: 0...</td>\n",
       "      <td>{(-11, -5): 1, (-7, -4): 1, (-7, -3): 1, (-5, ...</td>\n",
       "      <td>{(-9, -4): {2: 1}, (-5, -2): {2: 1}, (-3, -1):...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>{-11: 1, -7: 2, -5: 1, -3: 1, -1: 3, 1: 1, 3: 1}</td>\n",
       "      <td>{-5: 1, -4: 1, -3: 1, -2: 2, -1: 1, 0: 3, 1: 1}</td>\n",
       "      <td>{-5: -1, -4: 1, -3: -1, -2: 2, -1: -1, 0: 2, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>[2, 2, -1, 3, -1, -2, -2, -1, -1]</td>\n",
       "      <td>3</td>\n",
       "      <td>{-15: {-6: Z}, -13: {-6: 0, -5: Z x C2, -4: 0}...</td>\n",
       "      <td>{(-15, -6): 1, (-13, -5): 1, (-11, -5): 1, (-1...</td>\n",
       "      <td>{(-13, -5): {2: 1}, (-11, -4): {2: 1}, (-7, -2...</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>{-15: 1, -13: 1, -11: 3, -9: 5, -7: 2, -5: 2, ...</td>\n",
       "      <td>{-6: 1, -5: 2, -4: 5, -3: 2, -2: 4, -1: 2, 0: 4}</td>\n",
       "      <td>{-7: 1, -6: -2, -5: 3, -4: -2, -3: 4, -2: -2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2529</th>\n",
       "      <td>[2, -3, -3, 2, -3, -1, -2, -1, 2]</td>\n",
       "      <td>1</td>\n",
       "      <td>{-13: {-6: 0, -5: 0}, -11: {-6: 0, -5: 0, -4: ...</td>\n",
       "      <td>{(-9, -3): 1, (-5, -2): 1, (-3, 0): 1, (-1, 0)...</td>\n",
       "      <td>{(-7, -2): {2: 1}}</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{-9: 1, -5: 1, -3: 1, -1: 1}</td>\n",
       "      <td>{-3: 1, -2: 1, 0: 2}</td>\n",
       "      <td>{-4: -1, -3: 1, -1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2530</th>\n",
       "      <td>[-1, 2, -3, -1, -2, -2, -1, 3, 2]</td>\n",
       "      <td>3</td>\n",
       "      <td>{-13: {-6: 0, -5: Z}, -11: {-6: 0, -5: 0, -4: ...</td>\n",
       "      <td>{(-13, -5): 1, (-11, -4): 1, (-9, -4): 1, (-9,...</td>\n",
       "      <td>{(-11, -4): {2: 1}, (-9, -3): {2: 1}, (-7, -2)...</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>{-13: 1, -11: 1, -9: 2, -7: 4, -5: 4, -3: 3, -...</td>\n",
       "      <td>{-5: 1, -4: 2, -3: 2, -2: 6, -1: 2, 0: 5, 1: 1...</td>\n",
       "      <td>{-6: -1, -5: 2, -4: -2, -3: 4, -2: -2, -1: 3, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2531 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   braid  components  \\\n",
       "0         [2, 2, 1, -2, 2, 1, -1, -1, 2]           1   \n",
       "1     [-2, -1, 1, -3, -1, 2, -3, -2, -1]           1   \n",
       "2     [-3, -2, 3, -2, -1, -1, 1, -3, -1]           3   \n",
       "3          [3, 3, 2, 3, -1, -2, 2, 3, 3]           1   \n",
       "4      [-3, -3, 2, -2, 2, 1, -3, -3, -3]           1   \n",
       "...                                  ...         ...   \n",
       "2526   [3, 1, 3, -1, -1, -1, -1, -1, -1]           3   \n",
       "2527   [2, 2, 2, -1, -2, -3, -2, -1, -3]           1   \n",
       "2528   [2, 2, -1, 3, -1, -2, -2, -1, -1]           3   \n",
       "2529   [2, -3, -3, 2, -3, -1, -2, -1, 2]           1   \n",
       "2530   [-1, 2, -3, -1, -2, -2, -1, 3, 2]           3   \n",
       "\n",
       "                                      khovanov_homology  \\\n",
       "0     {1: {0: Z}, 3: {0: Z, 1: 0, 2: 0, 3: 0}, 5: {0...   \n",
       "1     {-13: {-6: 0, -5: Z, -4: 0}, -11: {-6: 0, -5: ...   \n",
       "2     {-15: {-6: Z}, -13: {-6: Z, -5: 0, -4: 0, -3: ...   \n",
       "3     {1: {-1: 0, 0: 0}, 3: {-1: 0, 0: Z, 1: 0, 2: 0...   \n",
       "4     {-15: {-5: Z}, -13: {-5: 0, -4: C2}, -11: {-5:...   \n",
       "...                                                 ...   \n",
       "2526  {-17: {-6: 0, -5: 0}, -15: {-6: 0, -5: Z, -4: ...   \n",
       "2527  {-11: {-6: 0, -5: Z, -4: 0}, -9: {-6: 0, -5: 0...   \n",
       "2528  {-15: {-6: Z}, -13: {-6: 0, -5: Z x C2, -4: 0}...   \n",
       "2529  {-13: {-6: 0, -5: 0}, -11: {-6: 0, -5: 0, -4: ...   \n",
       "2530  {-13: {-6: 0, -5: Z}, -11: {-6: 0, -5: 0, -4: ...   \n",
       "\n",
       "                                              free_part  \\\n",
       "0          {(1, 0): 1, (3, 0): 1, (5, 2): 1, (9, 3): 1}   \n",
       "1     {(-13, -5): 1, (-9, -4): 1, (-9, -3): 1, (-7, ...   \n",
       "2     {(-15, -6): 1, (-13, -6): 1, (-11, -4): 2, (-9...   \n",
       "3     {(3, 0): 1, (5, 0): 1, (7, 2): 1, (11, 3): 1, ...   \n",
       "4     {(-15, -5): 1, (-11, -4): 1, (-11, -3): 1, (-7...   \n",
       "...                                                 ...   \n",
       "2526  {(-15, -5): 1, (-13, -5): 1, (-11, -4): 1, (-1...   \n",
       "2527  {(-11, -5): 1, (-7, -4): 1, (-7, -3): 1, (-5, ...   \n",
       "2528  {(-15, -6): 1, (-13, -5): 1, (-11, -5): 1, (-1...   \n",
       "2529  {(-9, -3): 1, (-5, -2): 1, (-3, 0): 1, (-1, 0)...   \n",
       "2530  {(-13, -5): 1, (-11, -4): 1, (-9, -4): 1, (-9,...   \n",
       "\n",
       "                                           torsion_part  free_part_count  \\\n",
       "0                                      {(7, 3): {2: 1}}                4   \n",
       "1     {(-11, -4): {2: 1}, (-7, -2): {2: 1}, (-5, -1)...                8   \n",
       "2                  {(-9, -3): {2: 1}, (-5, -1): {2: 1}}               12   \n",
       "3                     {(9, 3): {2: 1}, (13, 5): {2: 1}}                6   \n",
       "4                 {(-13, -4): {2: 1}, (-9, -2): {2: 1}}                6   \n",
       "...                                                 ...              ...   \n",
       "2526  {(-13, -4): {2: 1}, (-11, -4): {2: 1}, (-9, -2...               24   \n",
       "2527  {(-9, -4): {2: 1}, (-5, -2): {2: 1}, (-3, -1):...               10   \n",
       "2528  {(-13, -5): {2: 1}, (-11, -4): {2: 1}, (-7, -2...               20   \n",
       "2529                                 {(-7, -2): {2: 1}}                4   \n",
       "2530  {(-11, -4): {2: 1}, (-9, -3): {2: 1}, (-7, -2)...               20   \n",
       "\n",
       "      torsion_part_count                               total_num_FP_per_row  \\\n",
       "0                      1                           {1: 1, 3: 1, 5: 1, 9: 1}   \n",
       "1                      3        {-13: 1, -9: 2, -7: 1, -5: 1, -3: 2, -1: 1}   \n",
       "2                      2  {-15: 1, -13: 1, -11: 2, -9: 1, -7: 3, -5: 1, ...   \n",
       "3                      2                   {3: 1, 5: 1, 7: 1, 11: 2, 15: 1}   \n",
       "4                      2              {-15: 1, -11: 2, -7: 1, -5: 1, -3: 1}   \n",
       "...                  ...                                                ...   \n",
       "2526                   8  {-15: 1, -13: 1, -11: 3, -9: 3, -7: 3, -5: 4, ...   \n",
       "2527                   4   {-11: 1, -7: 2, -5: 1, -3: 1, -1: 3, 1: 1, 3: 1}   \n",
       "2528                   6  {-15: 1, -13: 1, -11: 3, -9: 5, -7: 2, -5: 2, ...   \n",
       "2529                   1                       {-9: 1, -5: 1, -3: 1, -1: 1}   \n",
       "2530                   6  {-13: 1, -11: 1, -9: 2, -7: 4, -5: 4, -3: 3, -...   \n",
       "\n",
       "                                total_num_FP_per_column  \\\n",
       "0                                    {0: 2, 2: 1, 3: 1}   \n",
       "1             {-5: 1, -4: 1, -3: 1, -2: 2, -1: 1, 0: 2}   \n",
       "2             {-6: 2, -4: 3, -3: 1, -2: 3, -1: 1, 0: 2}   \n",
       "3                        {0: 2, 2: 1, 3: 1, 4: 1, 5: 1}   \n",
       "4                    {-5: 1, -4: 1, -3: 1, -2: 1, 0: 2}   \n",
       "...                                                 ...   \n",
       "2526    {-5: 2, -4: 2, -3: 4, -2: 4, -1: 2, 0: 6, 2: 4}   \n",
       "2527    {-5: 1, -4: 1, -3: 1, -2: 2, -1: 1, 0: 3, 1: 1}   \n",
       "2528   {-6: 1, -5: 2, -4: 5, -3: 2, -2: 4, -1: 2, 0: 4}   \n",
       "2529                               {-3: 1, -2: 1, 0: 2}   \n",
       "2530  {-5: 1, -4: 2, -3: 2, -2: 6, -1: 2, 0: 5, 1: 1...   \n",
       "\n",
       "                                       jones_polynomial  \n",
       "0                                   {1: 1, 3: 1, 4: -1}  \n",
       "1         {-6: -1, -5: 1, -4: -1, -3: 2, -2: -1, -1: 1}  \n",
       "2          {-7: 1, -5: 2, -4: -1, -3: 2, -2: -1, -1: 1}  \n",
       "3                      {2: 1, 4: 1, 5: -1, 6: 1, 7: -1}  \n",
       "4                 {-7: -1, -6: 1, -5: -1, -4: 1, -2: 1}  \n",
       "...                                                 ...  \n",
       "2526  {-7: -1, -5: -1, -3: 1, -2: 1, -1: 2, 0: 1, 1: 1}  \n",
       "2527  {-5: -1, -4: 1, -3: -1, -2: 2, -1: -1, 0: 2, 1...  \n",
       "2528  {-7: 1, -6: -2, -5: 3, -4: -2, -3: 4, -2: -2, ...  \n",
       "2529                             {-4: -1, -3: 1, -1: 1}  \n",
       "2530  {-6: -1, -5: 2, -4: -2, -3: 4, -2: -2, -1: 3, ...  \n",
       "\n",
       "[2531 rows x 10 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9621150e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x7fa750a11ac0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at data distribution using seaborn plot\n",
    "sns.pairplot(df[['free_part_count','torsion_part_count']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0eaad1",
   "metadata": {},
   "source": [
    "# Step2. Trian the LinearRegression Model&PolynomialRegression Model and find the parameters using the function we built ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3fe527da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T00:26:25.507037Z",
     "start_time": "2022-12-05T00:26:25.502756Z"
    }
   },
   "outputs": [],
   "source": [
    "#Import functions built in class\n",
    "from scripts.predict_accuracy import prediction, accuracy\n",
    "from scripts.GDLinearReg import J, DJ, GD_linreg_improved,fit,add_poly_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "488c78e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T00:26:26.752380Z",
     "start_time": "2022-12-05T00:26:26.743545Z"
    }
   },
   "outputs": [],
   "source": [
    "X = (np.array(df.free_part_count)).reshape(-1, 1)\n",
    "y = (np.array(df.torsion_part_count)).reshape(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7246a8b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T00:26:27.501140Z",
     "start_time": "2022-12-05T00:26:27.495115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 1518\n",
      "Size of validation set: 506\n",
      "Size of testing set: 507\n"
     ]
    }
   ],
   "source": [
    "print(f'Size of training set: {len(X_train)}')\n",
    "print(f'Size of validation set: {len(X_val)}')\n",
    "print(f'Size of testing set: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "db8bba7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running polynomial regression of degree 1 \n",
      "\n",
      "After 0 steps the cost is 37.69038208168644\n",
      "After 9 steps the cost is 1.915558034227914\n",
      "\n",
      "Final cost is 1.915558034227833\n",
      "\n",
      "Accuracy of training set is: 0.11725955204216074\n",
      "Accuracy of validation set is: 0.12450592885375494\n",
      "Accuracy of test set is: 0.11637080867850098\n",
      "[[-1.73216406]\n",
      " [ 0.45056383]]\n"
     ]
    }
   ],
   "source": [
    "# predict with 1,2,3 components link Linear Regression\n",
    "degree = 1\n",
    "\n",
    "v, costs = fit(X_train, y_train, epsilon = 1e-10, lambda_ = 0, max_iters = 10000, poly_terms = degree)\n",
    "\n",
    "print(f'Accuracy of training set is: {accuracy(add_poly_terms(X_train, degree),v,y_train)}')\n",
    "print(f'Accuracy of validation set is: {accuracy(add_poly_terms(X_val, degree),v,y_val)}')\n",
    "print(f'Accuracy of test set is: {accuracy(add_poly_terms(X_test, degree),v,y_test)}')\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9998bd13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T00:26:40.146433Z",
     "start_time": "2022-12-05T00:26:39.723041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running polynomial regression of degree 2 \n",
      "\n",
      "After 0 steps the cost is 37.69038208168644\n",
      "After 1000 steps the cost is 1.7294262169070482\n",
      "After 2000 steps the cost is 1.7223811562315872\n",
      "After 3000 steps the cost is 1.7215426863722545\n",
      "After 4000 steps the cost is 1.7214428956397885\n",
      "After 5000 steps the cost is 1.721431019010098\n",
      "After 6000 steps the cost is 1.721429605510707\n",
      "After 6660 steps the cost is 1.7214294614185082\n",
      "\n",
      "Final cost is 1.7214294613188657\n",
      "\n",
      "Accuracy of training set is: 0.19696969696969696\n",
      "Accuracy of validation set is: 0.16996047430830039\n",
      "Accuracy of test set is: 0.17751479289940827\n",
      "[[-0.7375422 ]\n",
      " [ 0.32638822]\n",
      " [ 0.0027388 ]]\n"
     ]
    }
   ],
   "source": [
    "# predict with 1,2,3 components Polynomial Regression\n",
    "degree = 2\n",
    "\n",
    "v, costs = fit(X_train, y_train, epsilon = 1e-10, lambda_ = 0, max_iters = 10000, poly_terms = degree)\n",
    "\n",
    "print(f'Accuracy of training set is: {accuracy(add_poly_terms(X_train, degree),v,y_train)}')\n",
    "print(f'Accuracy of validation set is: {accuracy(add_poly_terms(X_val, degree),v,y_val)}')\n",
    "print(f'Accuracy of test set is: {accuracy(add_poly_terms(X_test, degree),v,y_test)}')\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "484f92f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df[df.components == 1][\"free_part_count\"].to_numpy().reshape(-1,1)\n",
    "Y1 = df[df.components == 1][\"torsion_part_count\"].to_numpy().reshape(-1,1)\n",
    "X2 = df[df.components == 2][\"free_part_count\"].to_numpy().reshape(-1,1)\n",
    "Y2 = df[df.components == 2][\"torsion_part_count\"].to_numpy().reshape(-1,1)\n",
    "X3 = df[df.components == 3][\"free_part_count\"].to_numpy().reshape(-1,1)\n",
    "Y3 = df[df.components == 3][\"torsion_part_count\"].to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e0e52231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with 1 component link\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d8ae7b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running polynomial regression of degree 1 \n",
      "\n",
      "After 0 steps the cost is 34.95317220543806\n",
      "After 7 steps the cost is 0.0593826548764601\n",
      "\n",
      "Final cost is 0.059382654875744276\n",
      "\n",
      "Accuracy of training set is: 0.9848942598187311\n",
      "Accuracy of validation set is: 0.9864253393665159\n",
      "Accuracy of test set is: 0.9683257918552036\n",
      "[[-1.04602122]\n",
      " [ 0.50144838]]\n"
     ]
    }
   ],
   "source": [
    "degree = 1\n",
    "\n",
    "v, costs = fit(X_train, y_train, epsilon = 1e-10, lambda_ = 0, max_iters = 10000, poly_terms = degree)\n",
    "\n",
    "print(f'Accuracy of training set is: {accuracy(add_poly_terms(X_train, degree),v,y_train)}')\n",
    "print(f'Accuracy of validation set is: {accuracy(add_poly_terms(X_val, degree),v,y_val)}')\n",
    "print(f'Accuracy of test set is: {accuracy(add_poly_terms(X_test, degree),v,y_test)}')\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2b2865e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with 2 component link\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, Y2, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b178fbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running polynomial regression of degree 1 \n",
      "\n",
      "After 0 steps the cost is 27.086956521739136\n",
      "After 10 steps the cost is 0.04298997741997323\n",
      "\n",
      "Final cost is 0.042989977418824106\n",
      "\n",
      "Accuracy of training set is: 0.9891304347826086\n",
      "Accuracy of validation set is: 0.9838709677419355\n",
      "Accuracy of test set is: 0.9838709677419355\n",
      "[[-2.0278167 ]\n",
      " [ 0.50053558]]\n"
     ]
    }
   ],
   "source": [
    "degree = 1\n",
    "\n",
    "v, costs = fit(X_train, y_train, epsilon = 1e-10, lambda_ = 0, max_iters = 10000, poly_terms = degree)\n",
    "\n",
    "print(f'Accuracy of training set is: {accuracy(add_poly_terms(X_train, degree),v,y_train)}')\n",
    "print(f'Accuracy of validation set is: {accuracy(add_poly_terms(X_val, degree),v,y_val)}')\n",
    "print(f'Accuracy of test set is: {accuracy(add_poly_terms(X_test, degree),v,y_test)}')\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a340cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with 3 component link\n",
    "X_train, X_test, y_train, y_test = train_test_split(X3, Y3, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f36dcfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running polynomial regression of degree 1 \n",
      "\n",
      "After 0 steps the cost is 38.46795827123695\n",
      "After 12 steps the cost is 0.4742676222943943\n",
      "\n",
      "Final cost is 0.47426762229265484\n",
      "\n",
      "Accuracy of training set is: 0.9597615499254843\n",
      "Accuracy of validation set is: 0.9508928571428571\n",
      "Accuracy of test set is: 0.9508928571428571\n",
      "[[-4.24670737]\n",
      " [ 0.51874705]]\n"
     ]
    }
   ],
   "source": [
    "degree = 1\n",
    "\n",
    "v, costs = fit(X_train, y_train, epsilon = 1e-10, lambda_ = 0, max_iters = 10000, poly_terms = degree)\n",
    "\n",
    "print(f'Accuracy of training set is: {accuracy(add_poly_terms(X_train, degree),v,y_train)}')\n",
    "print(f'Accuracy of validation set is: {accuracy(add_poly_terms(X_val, degree),v,y_val)}')\n",
    "print(f'Accuracy of test set is: {accuracy(add_poly_terms(X_test, degree),v,y_test)}')\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed0e93f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to test with the dataset that has 2_component link or 3-componet link.\n",
    "# also a dataset combined them together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a4c460",
   "metadata": {},
   "source": [
    "# Step3. Train the LinearRegression model from Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35cf7bea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T00:14:22.790272Z",
     "start_time": "2022-12-05T00:14:22.781443Z"
    }
   },
   "outputs": [],
   "source": [
    "# try to make prediction using LinearRegression and libraries from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# need to reshape X because there is only one feature in X (i.e. X is currently a row vector, need to convert it to a column vector)\n",
    "X = (np.array(df.free_part_count)).reshape(-1, 1)\n",
    "y = (np.array(df.torsion_part_count))\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5993a08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T00:07:09.899898Z",
     "start_time": "2022-12-05T00:07:09.896042Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries for Polynomial Regression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d31bdbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute accuracy\n",
    "def find_accuracy(y_pred, y_true):\n",
    "    accur_count = 0\n",
    "    for index,y in enumerate(y_pred):\n",
    "        if y == math.ceil(y_true[index]):\n",
    "            accur_count += 1\n",
    "    return accur_count/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "727551fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T00:17:05.383237Z",
     "start_time": "2022-12-05T00:17:05.312434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Features: [1,x,x**2,...,x**1]\n",
      "[ 1. 10.]\n",
      "Polynomial Features: [1,x,x**2,...,x**1]\n",
      "[1. 4.]\n",
      "Polynomial Features: [1,x,x**2,...,x**1]\n",
      "[ 1. 14.]\n",
      "Polynomial Features: [1,x,x**2,...,x**2]\n",
      "[  1.  10. 100.]\n",
      "Polynomial Features: [1,x,x**2,...,x**2]\n",
      "[ 1.  4. 16.]\n",
      "Polynomial Features: [1,x,x**2,...,x**2]\n",
      "[  1.  14. 196.]\n",
      "Polynomial Features: [1,x,x**2,...,x**3]\n",
      "[   1.   10.  100. 1000.]\n",
      "Polynomial Features: [1,x,x**2,...,x**3]\n",
      "[ 1.  4. 16. 64.]\n",
      "Polynomial Features: [1,x,x**2,...,x**3]\n",
      "[1.000e+00 1.400e+01 1.960e+02 2.744e+03]\n",
      "Polynomial Features: [1,x,x**2,...,x**4]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04]\n",
      "Polynomial Features: [1,x,x**2,...,x**4]\n",
      "[  1.   4.  16.  64. 256.]\n",
      "Polynomial Features: [1,x,x**2,...,x**4]\n",
      "[1.0000e+00 1.4000e+01 1.9600e+02 2.7440e+03 3.8416e+04]\n",
      "Polynomial Features: [1,x,x**2,...,x**5]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04 1.e+05]\n",
      "Polynomial Features: [1,x,x**2,...,x**5]\n",
      "[1.000e+00 4.000e+00 1.600e+01 6.400e+01 2.560e+02 1.024e+03]\n",
      "Polynomial Features: [1,x,x**2,...,x**5]\n",
      "[1.00000e+00 1.40000e+01 1.96000e+02 2.74400e+03 3.84160e+04 5.37824e+05]\n",
      "Polynomial Features: [1,x,x**2,...,x**6]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04 1.e+05 1.e+06]\n",
      "Polynomial Features: [1,x,x**2,...,x**6]\n",
      "[1.000e+00 4.000e+00 1.600e+01 6.400e+01 2.560e+02 1.024e+03 4.096e+03]\n",
      "Polynomial Features: [1,x,x**2,...,x**6]\n",
      "[1.000000e+00 1.400000e+01 1.960000e+02 2.744000e+03 3.841600e+04\n",
      " 5.378240e+05 7.529536e+06]\n",
      "Polynomial Features: [1,x,x**2,...,x**7]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04 1.e+05 1.e+06 1.e+07]\n",
      "Polynomial Features: [1,x,x**2,...,x**7]\n",
      "[1.0000e+00 4.0000e+00 1.6000e+01 6.4000e+01 2.5600e+02 1.0240e+03\n",
      " 4.0960e+03 1.6384e+04]\n",
      "Polynomial Features: [1,x,x**2,...,x**7]\n",
      "[1.00000000e+00 1.40000000e+01 1.96000000e+02 2.74400000e+03\n",
      " 3.84160000e+04 5.37824000e+05 7.52953600e+06 1.05413504e+08]\n",
      "Polynomial Features: [1,x,x**2,...,x**8]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04 1.e+05 1.e+06 1.e+07 1.e+08]\n",
      "Polynomial Features: [1,x,x**2,...,x**8]\n",
      "[1.0000e+00 4.0000e+00 1.6000e+01 6.4000e+01 2.5600e+02 1.0240e+03\n",
      " 4.0960e+03 1.6384e+04 6.5536e+04]\n",
      "Polynomial Features: [1,x,x**2,...,x**8]\n",
      "[1.00000000e+00 1.40000000e+01 1.96000000e+02 2.74400000e+03\n",
      " 3.84160000e+04 5.37824000e+05 7.52953600e+06 1.05413504e+08\n",
      " 1.47578906e+09]\n",
      "Polynomial Features: [1,x,x**2,...,x**9]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04 1.e+05 1.e+06 1.e+07 1.e+08 1.e+09]\n",
      "Polynomial Features: [1,x,x**2,...,x**9]\n",
      "[1.00000e+00 4.00000e+00 1.60000e+01 6.40000e+01 2.56000e+02 1.02400e+03\n",
      " 4.09600e+03 1.63840e+04 6.55360e+04 2.62144e+05]\n",
      "Polynomial Features: [1,x,x**2,...,x**9]\n",
      "[1.00000000e+00 1.40000000e+01 1.96000000e+02 2.74400000e+03\n",
      " 3.84160000e+04 5.37824000e+05 7.52953600e+06 1.05413504e+08\n",
      " 1.47578906e+09 2.06610468e+10]\n",
      "Polynomial Features: [1,x,x**2,...,x**10]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04 1.e+05 1.e+06 1.e+07 1.e+08 1.e+09\n",
      " 1.e+10]\n",
      "Polynomial Features: [1,x,x**2,...,x**10]\n",
      "[1.000000e+00 4.000000e+00 1.600000e+01 6.400000e+01 2.560000e+02\n",
      " 1.024000e+03 4.096000e+03 1.638400e+04 6.553600e+04 2.621440e+05\n",
      " 1.048576e+06]\n",
      "Polynomial Features: [1,x,x**2,...,x**10]\n",
      "[1.00000000e+00 1.40000000e+01 1.96000000e+02 2.74400000e+03\n",
      " 3.84160000e+04 5.37824000e+05 7.52953600e+06 1.05413504e+08\n",
      " 1.47578906e+09 2.06610468e+10 2.89254655e+11]\n",
      "Polynomial Features: [1,x,x**2,...,x**11]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04 1.e+05 1.e+06 1.e+07 1.e+08 1.e+09\n",
      " 1.e+10 1.e+11]\n",
      "Polynomial Features: [1,x,x**2,...,x**11]\n",
      "[1.000000e+00 4.000000e+00 1.600000e+01 6.400000e+01 2.560000e+02\n",
      " 1.024000e+03 4.096000e+03 1.638400e+04 6.553600e+04 2.621440e+05\n",
      " 1.048576e+06 4.194304e+06]\n",
      "Polynomial Features: [1,x,x**2,...,x**11]\n",
      "[1.00000000e+00 1.40000000e+01 1.96000000e+02 2.74400000e+03\n",
      " 3.84160000e+04 5.37824000e+05 7.52953600e+06 1.05413504e+08\n",
      " 1.47578906e+09 2.06610468e+10 2.89254655e+11 4.04956517e+12]\n",
      "Polynomial Features: [1,x,x**2,...,x**12]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04 1.e+05 1.e+06 1.e+07 1.e+08 1.e+09\n",
      " 1.e+10 1.e+11 1.e+12]\n",
      "Polynomial Features: [1,x,x**2,...,x**12]\n",
      "[1.0000000e+00 4.0000000e+00 1.6000000e+01 6.4000000e+01 2.5600000e+02\n",
      " 1.0240000e+03 4.0960000e+03 1.6384000e+04 6.5536000e+04 2.6214400e+05\n",
      " 1.0485760e+06 4.1943040e+06 1.6777216e+07]\n",
      "Polynomial Features: [1,x,x**2,...,x**12]\n",
      "[1.00000000e+00 1.40000000e+01 1.96000000e+02 2.74400000e+03\n",
      " 3.84160000e+04 5.37824000e+05 7.52953600e+06 1.05413504e+08\n",
      " 1.47578906e+09 2.06610468e+10 2.89254655e+11 4.04956517e+12\n",
      " 5.66939124e+13]\n",
      "Polynomial Features: [1,x,x**2,...,x**13]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04 1.e+05 1.e+06 1.e+07 1.e+08 1.e+09\n",
      " 1.e+10 1.e+11 1.e+12 1.e+13]\n",
      "Polynomial Features: [1,x,x**2,...,x**13]\n",
      "[1.0000000e+00 4.0000000e+00 1.6000000e+01 6.4000000e+01 2.5600000e+02\n",
      " 1.0240000e+03 4.0960000e+03 1.6384000e+04 6.5536000e+04 2.6214400e+05\n",
      " 1.0485760e+06 4.1943040e+06 1.6777216e+07 6.7108864e+07]\n",
      "Polynomial Features: [1,x,x**2,...,x**13]\n",
      "[1.00000000e+00 1.40000000e+01 1.96000000e+02 2.74400000e+03\n",
      " 3.84160000e+04 5.37824000e+05 7.52953600e+06 1.05413504e+08\n",
      " 1.47578906e+09 2.06610468e+10 2.89254655e+11 4.04956517e+12\n",
      " 5.66939124e+13 7.93714773e+14]\n",
      "Polynomial Features: [1,x,x**2,...,x**14]\n",
      "[1.e+00 1.e+01 1.e+02 1.e+03 1.e+04 1.e+05 1.e+06 1.e+07 1.e+08 1.e+09\n",
      " 1.e+10 1.e+11 1.e+12 1.e+13 1.e+14]\n",
      "Polynomial Features: [1,x,x**2,...,x**14]\n",
      "[1.00000000e+00 4.00000000e+00 1.60000000e+01 6.40000000e+01\n",
      " 2.56000000e+02 1.02400000e+03 4.09600000e+03 1.63840000e+04\n",
      " 6.55360000e+04 2.62144000e+05 1.04857600e+06 4.19430400e+06\n",
      " 1.67772160e+07 6.71088640e+07 2.68435456e+08]\n",
      "Polynomial Features: [1,x,x**2,...,x**14]\n",
      "[1.00000000e+00 1.40000000e+01 1.96000000e+02 2.74400000e+03\n",
      " 3.84160000e+04 5.37824000e+05 7.52953600e+06 1.05413504e+08\n",
      " 1.47578906e+09 2.06610468e+10 2.89254655e+11 4.04956517e+12\n",
      " 5.66939124e+13 7.93714773e+14 1.11120068e+16]\n"
     ]
    }
   ],
   "source": [
    "# Find the degree of Polynomial Regression that gives the best prediction accuracy\n",
    "model_degrees_and_scores = {}\n",
    "model_degrees_and_accuracy = {}\n",
    "for current_degree in range(1,15):\n",
    "    polynomial_features= PolynomialFeatures(degree=current_degree)\n",
    "    X_poly_train_deg = polynomial_features.fit_transform(X_train)\n",
    "    print(f'Polynomial Features: [1,x,x**2,...,x**{current_degree}]')\n",
    "    print(X_poly_train_deg[0])\n",
    "    \n",
    "    X_poly_val_deg = polynomial_features.fit_transform(X_val)\n",
    "    print(f'Polynomial Features: [1,x,x**2,...,x**{current_degree}]')\n",
    "    print(X_poly_val_deg[0])\n",
    "    \n",
    "\n",
    "    X_poly_test_deg = polynomial_features.fit_transform(X_test)\n",
    "    print(f'Polynomial Features: [1,x,x**2,...,x**{current_degree}]')\n",
    "    print(X_poly_test_deg[0])\n",
    "\n",
    "    polyreg = LinearRegression().fit(X_poly_train_deg, y_train)\n",
    "    \n",
    "    train_score = polyreg.score(X_poly_train_deg,y_train)\n",
    "    val_score = polyreg.score(X_poly_val_deg,y_val)\n",
    "    test_score = polyreg.score(X_poly_test_deg,y_test)\n",
    "        \n",
    "    y_train_pred = polyreg.predict(X_poly_train_deg)\n",
    "    y_val_pred = polyreg.predict(X_poly_val_deg)\n",
    "    y_test_pred = polyreg.predict(X_poly_test_deg)\n",
    "    train_accuracy = find_accuracy(y_train, y_train_pred)\n",
    "    val_accuracy = find_accuracy(y_val, y_val_pred)\n",
    "    test_accuracy = find_accuracy(y_test, y_test_pred)\n",
    "    \n",
    "    model_degrees_and_scores[current_degree] = (train_score, val_score, test_score)\n",
    "    model_degrees_and_accuracy[current_degree] = (train_accuracy, val_accuracy, test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a5de91b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T00:22:44.760390Z",
     "start_time": "2022-12-05T00:22:44.753551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 1 scores: (0.9961854542032902, 0.996689906167883, 0.9986253583557888)\n",
      "Degree 2 scores: (0.9961855431112161, 0.9966895074290567, 0.9986249143257563)\n",
      "Degree 3 scores: (0.9961932965785659, 0.9966981368106852, 0.9986212759008535)\n",
      "Degree 4 scores: (0.996219219700024, 0.9967179279103181, 0.998606321386437)\n",
      "Degree 5 scores: (0.9962596431360705, 0.9967519307061131, 0.998581222802471)\n",
      "Degree 6 scores: (0.9962954369649488, 0.996767244909191, 0.998557268965047)\n",
      "Degree 7 scores: (0.9963098365320182, 0.9967699981628567, 0.9985500241346432)\n",
      "Degree 8 scores: (0.9963105464454888, 0.9967680059963694, 0.9985490659396984)\n",
      "Degree 9 scores: (0.9963072188838022, 0.9967600761688417, 0.9985332524282866)\n",
      "Degree 10 scores: (0.9914089185049131, 0.9905652177069153, 0.9915613731545233)\n",
      "Degree 11 scores: (0.9768961727036134, 0.9755531682353894, 0.9735762151174491)\n",
      "Degree 12 scores: (0.9509284710094854, 0.948162826290044, 0.9365058987896278)\n",
      "Degree 13 scores: (0.9122816148839594, 0.9053223194910859, 0.8848826725937541)\n",
      "Degree 14 scores: (0.7593371541072363, 0.7303381104310236, 0.6943945842316875)\n"
     ]
    }
   ],
   "source": [
    "for i, scores in model_degrees_and_scores.items():\n",
    "    print(f'Degree {i} scores: {scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e13db6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 1 scores: (0.9567901234567902, 0.9537037037037037, 0.9631336405529954)\n",
      "Degree 2 scores: (0.9567901234567902, 0.9537037037037037, 0.9631336405529954)\n",
      "Degree 3 scores: (0.9290123456790124, 0.9166666666666666, 0.9447004608294931)\n",
      "Degree 4 scores: (0.8981481481481481, 0.9120370370370371, 0.8940092165898618)\n",
      "Degree 5 scores: (0.8472222222222222, 0.875, 0.8663594470046083)\n",
      "Degree 6 scores: (0.5817901234567902, 0.5925925925925926, 0.6129032258064516)\n",
      "Degree 7 scores: (0.5987654320987654, 0.5879629629629629, 0.6267281105990783)\n",
      "Degree 8 scores: (0.5416666666666666, 0.5277777777777778, 0.5391705069124424)\n",
      "Degree 9 scores: (0.5555555555555556, 0.5138888888888888, 0.5483870967741935)\n",
      "Degree 10 scores: (0.558641975308642, 0.5092592592592593, 0.543778801843318)\n",
      "Degree 11 scores: (0.5740740740740741, 0.5787037037037037, 0.6036866359447005)\n",
      "Degree 12 scores: (0.24228395061728394, 0.25, 0.2764976958525346)\n",
      "Degree 13 scores: (0.14351851851851852, 0.12037037037037036, 0.1889400921658986)\n",
      "Degree 14 scores: (0.1388888888888889, 0.13425925925925927, 0.1152073732718894)\n"
     ]
    }
   ],
   "source": [
    "for i, accuracy in model_degrees_and_accuracy.items():\n",
    "    print(f'Degree {i} scores: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
